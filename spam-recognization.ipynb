{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n\n      49   50     51     52     53     54   55    56  57  \n0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.778</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.756</td>\n      <td>61</td>\n      <td>278</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 58 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('spambase.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we clean the data.\n",
    "Check the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4601, 58)"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there's any NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data does not have NaNs.\n",
    "\n",
    "Since all attributes are useful for spam recognization, we do not need to remove any columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df.drop(57, axis=1), df[57], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(random_state=13)"
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=13)\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9587404994571118"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "predicted = model.predict(test_x)\n",
    "model.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "probabilities = model.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.985902264715824"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "roc_auc_score(test_y, probabilities[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[522,   9],\n       [ 29, 361]])"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9992972593113141"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "train_predictions = model.predict(train_x)\n",
    "precision_score(train_y, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9992972593113141"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(train_y, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_word_frequency(content):\n",
    "    words = ['make', 'address', 'all', '3d', 'our', 'over', 'remove', 'internet', 'order', 'mail', 'receive', 'will', 'people', 'report', 'addresses', 'free', 'business', 'email', 'you', 'credit', 'your', 'font', '000', 'money', 'hp', 'hpl', 'george', '650', 'lab', 'labs', 'telnet', '857', 'data', '415', '85','technology', '1999', 'parts', 'pm', 'direct', 'cs', 'meeting', 'original', 'project', 're', 'edu', 'table', 'conference']\n",
    "    chars = [';', '(', \"]\", '!', '$', '#']\n",
    "\n",
    "    # Find all words and its length\n",
    "    pattern_word = re.compile(r'[a-zA-Z\\d]+')\n",
    "    content_words = pattern_word.findall(content)\n",
    "    num_words = len(content_words)\n",
    "    # Calculate the frequency probability\n",
    "    frequency_word = [content_words.count(word) for word in words]\n",
    "    word_freqs = [100*freq/num_words for freq in frequency_word]\n",
    "\n",
    "    # Find all chars\n",
    "    num_chars = len(content)\n",
    "    frequency_char = [content.count(char) for char in chars]\n",
    "    char_freqs = [100*freq/num_chars for freq in frequency_char]\n",
    "\n",
    "    # Find the uninterrupted sequences of capital letters\n",
    "    pattern_capital = re.compile(r'[A-Z]+')\n",
    "    capital_words = pattern_capital.findall(content)\n",
    "    num_capitals = len(capital_words)\n",
    "    longest_capital = max(capital_words, key=len) if num_capitals > 0 else ''\n",
    "    len_longest_capital = len(longest_capital)\n",
    "    length_capitals = sum(list(map(len, capital_words)))\n",
    "    average_length = length_capitals/num_capitals if num_capitals > 0 else 0\n",
    "\n",
    "    # Final values\n",
    "    values = []\n",
    "    values.extend(word_freqs)\n",
    "    values.extend(char_freqs)\n",
    "    values.append(average_length)\n",
    "    values.append(len_longest_capital)\n",
    "    values.append(length_capitals)\n",
    "\n",
    "    return dict(enumerate(values))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spam(content):\n",
    "    input = [get_word_frequency(content)]\n",
    "    return model.predict(pd.DataFrame(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0])"
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "predict_spam(\"\"\"Hi Cheng ,\n",
    "\n",
    "This is an important reminder for those completing the non-technical stream for the second project (Azure & Cloud Fundamentals):\n",
    "\n",
    "You need to ensure that when you are choosing â€˜Database Providerâ€™ to set up your WordPress application, you select MySQL in App. Choosing anything else will spend all your credits.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1])"
     },
     "metadata": {},
     "execution_count": 204
    }
   ],
   "source": [
    "predict_spam(\"\"\"\n",
    "\n",
    "PUBLIC ANNOUNCEMENT:\n",
    "\n",
    "The new domain names are finally available to the general public at discount prices. Now you can register one of the exciting new .BIZ or .INFO domain names, as well as the original .COM and .NET names for just $14.95. These brand new domain extensions were recently approved by ICANN and have the same rights as the original .COM and .NET domain names. The biggest benefit is of-course that the .BIZ and .INFO domain names are currently more available. i.e. it will be much easier to register an attractive and easy-to-remember domain name for the same price.  \n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"spam_ham_dataset.csv\")\n",
    "test_df = test_df[['text', 'label_num']]\n",
    "\n",
    "test_input = []\n",
    "for i in range(test_df.shape[0]):\n",
    "    test_input.append(get_word_frequency(test_df.iloc[i][0]))\n",
    "test_input = pd.DataFrame(test_input)\n",
    "\n",
    "test_result = test_df['label_num']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7412492748017792"
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "model.score(test_input, test_result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitb7a13a9b0698444ab813f01f08c2c1b6",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}